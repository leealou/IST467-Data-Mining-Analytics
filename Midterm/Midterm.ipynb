{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Midterm \n",
    "1. Must in a WORD format to answer the asked questions\n",
    "2. Must explain your findings. Screenshots alone without clear explanations will not receive points. \n",
    "3. Complete the tasks, e.g., import libraries and files in the given document. You may need to install additional libraries to run the program.\n",
    "4. Any caught plagiarism will lead to 0 points and an F for the final grade. \n",
    "5. If I doubt about your answers, I will ask you to run your program in front of me and ask you questions during the class or my office hours. \n",
    "If you cannot answer my questions, you will receive a 0 for your midterm.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Q1 import NLTK\n",
    "import nltk as nltk\n",
    "# Q1 import xgboost as xgb\n",
    "import xgboost as xgb\n",
    "# Q1 import Word2Vec from gensim.models\n",
    "import gensim\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Concatenate, Reshape, Dropout, BatchNormalization, Embedding, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 100\n",
    "EMBEDDING_DIM = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1 laod the movie_reviews.csv with encoding 'latin-1'\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\Alexi\\\\OneDrive - Cleveland State University\\\\Senior Year 2021-2022\\\\Data Mining + Analytics\\\\Midterm/movie_reviews.csv\", encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.SentimentText = data.SentimentText.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \n",
    "    string = re.sub(r\"https?\\://\\S+\", '', string)\n",
    "    string = re.sub(r'\\<a href', ' ', string)\n",
    "    string = re.sub(r'&amp;', '', string) \n",
    "    string = re.sub(r'<br />', ' ', string)\n",
    "    string = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', string)\n",
    "    string = re.sub('\\d','', string)\n",
    "    string = re.sub(r\"can\\'t\", \"cannot\", string)\n",
    "    string = re.sub(r\"it\\'s\", \"it is\", string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.SentimentText = data.SentimentText.apply(lambda x: clean_str(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie    43558\n",
       "film     39095\n",
       "it       30659\n",
       "one      26509\n",
       "is       20355\n",
       "like     20270\n",
       "good     15099\n",
       "the      13913\n",
       "time     12682\n",
       "even     12656\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(' '.join(data['SentimentText']).split()).value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english') + ['movie', 'film', 'time']\n",
    "stop_words = set(stop_words)\n",
    "remove_stop_words = lambda r: [[word for word in word_tokenize(sente) if word not in stop_words] for sente in sent_tokenize(r)]\n",
    "data['SentimentText'] = data['SentimentText'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(\n",
    "        data['SentimentText'].apply(lambda x: x[0]),\n",
    "        epochs=10,\n",
    "        vector_size=16,\n",
    "        window=5,\n",
    "        min_count=5,\n",
    "        workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lighten', 0.8160282373428345),\n",
       " ('entertaining', 0.8113067746162415),\n",
       " ('enjoyable', 0.8016651272773743),\n",
       " ('laughs', 0.7974727153778076),\n",
       " ('lighthearted', 0.7962534427642822),\n",
       " ('enjoy', 0.7910175919532776),\n",
       " ('comedy', 0.7804853320121765),\n",
       " ('funny', 0.7662642002105713),\n",
       " ('unintentional', 0.7638046741485596),\n",
       " ('laugh', 0.7572214603424072)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('fun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1799</td>\n",
       "      <td>654</td>\n",
       "      <td>2453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>613</td>\n",
       "      <td>1934</td>\n",
       "      <td>2547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>2412</td>\n",
       "      <td>2588</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0     1   All\n",
       "Actual                     \n",
       "0          1799   654  2453\n",
       "1           613  1934  2547\n",
       "All        2412  2588  5000"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_actual, y_pred, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('movie_embedding.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text(text):    \n",
    "    try:\n",
    "        return ' '.join(text[0])\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.SentimentText = data.SentimentText.apply(lambda x: combine_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 77297 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(list(data['SentimentText']))\n",
    "sequences = tokenizer.texts_to_sequences(data['SentimentText'])\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding(filename, word_index , num_words, embedding_dim):\n",
    "    embeddings_index = {}\n",
    "    file = open(filename, encoding=\"utf-8\")\n",
    "    for line in file:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coef = np.asarray(values[1:])\n",
    "        embeddings_index[word] = coef\n",
    "    file.close()\n",
    "    \n",
    "    embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "    for word, pos in word_index.items():\n",
    "        if pos >= num_words:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[pos] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = load_embedding('movie_embedding.txt', word_index, len(word_index), EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reviews, pd.get_dummies(data.Sentiment), test_size=0.2, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input((MAX_SEQUENCE_LENGTH,))\n",
    "embedding_layer = Embedding(len(word_index),\n",
    "                    EMBEDDING_DIM,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=MAX_SEQUENCE_LENGTH,\n",
    "                    trainable=False)(inp)\n",
    "model = Flatten()(embedding_layer)\n",
    "model = BatchNormalization()(model)\n",
    "model = Dropout(0.10)(model)\n",
    "model = Dense(units=256, activation='relu')(model)\n",
    "model = Dense(units=64, activation='relu')(model)\n",
    "model = Dropout(0.5)(model)\n",
    "predictions = Dense(units=2, activation='softmax')(model)\n",
    "model = Model(inputs = inp, outputs = predictions)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 100, 16)           1236752   \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 1600)             6400      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               409856    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,669,586\n",
      "Trainable params: 429,634\n",
      "Non-trainable params: 1,239,952\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 4s 28ms/step - loss: 0.8297 - acc: 0.5148 - val_loss: 0.7105 - val_acc: 0.5622\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.7390 - acc: 0.5626 - val_loss: 0.6749 - val_acc: 0.6042\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.7008 - acc: 0.5933 - val_loss: 0.6538 - val_acc: 0.6422\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 0.6751 - acc: 0.6201 - val_loss: 0.6358 - val_acc: 0.6614\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.6530 - acc: 0.6408 - val_loss: 0.6186 - val_acc: 0.6826\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 0.6342 - acc: 0.6567 - val_loss: 0.6011 - val_acc: 0.7006\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 0.6137 - acc: 0.6813 - val_loss: 0.5831 - val_acc: 0.7176\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.5951 - acc: 0.6948 - val_loss: 0.5663 - val_acc: 0.7284\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 2s 19ms/step - loss: 0.5776 - acc: 0.7089 - val_loss: 0.5508 - val_acc: 0.7362\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.5640 - acc: 0.7186 - val_loss: 0.5373 - val_acc: 0.7434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21ee2d971f0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7434"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(preds, 1), np.argmax(y_test.values, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1747</td>\n",
       "      <td>706</td>\n",
       "      <td>2453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>577</td>\n",
       "      <td>1970</td>\n",
       "      <td>2547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>2324</td>\n",
       "      <td>2676</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0     1   All\n",
       "Actual                     \n",
       "0          1747   706  2453\n",
       "1           577  1970  2547\n",
       "All        2324  2676  5000"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual = pd.Series(np.argmax(y_test.values, axis=1), name='Actual')\n",
    "y_pred = pd.Series(np.argmax(preds, axis=1), name='Predicted')\n",
    "pd.crosstab(y_actual, y_pred, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: \n",
      "video store years ago rented husband enjoyed much bought vhs enjoyed ever since plot well need going point deserves repeated viewings americans especially n't going get jokes first around know n't funny touching sad ray daughter 's wedding cringe inducing karen calls tony brian attempts kiss finally woman black funny words music good soundtrack 've heard years dancing living room world every performance absolutely perfect bill portrayal ray man one many bad stephen perfect tony lovable player carried karen years appealing look makes women want actors equally brilliant ignore read see gem\n",
      "\n",
      "Predicted sentiment = Positive\n",
      "\n",
      "Actual sentiment = Positive\n"
     ]
    }
   ],
   "source": [
    "review_num  = 333\n",
    "print(\"Review: \\n\"+tokenizer.sequences_to_texts([X_test[review_num]])[0])\n",
    "sentiment = \"Positive\" if np.argmax(preds[review_num]) else \"Negative\"\n",
    "print(\"\\nPredicted sentiment = \"+ sentiment)\n",
    "sentiment = \"Positive\" if np.argmax(y_test.values[review_num]) else \"Negative\"\n",
    "print(\"\\nActual sentiment = \"+ sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
