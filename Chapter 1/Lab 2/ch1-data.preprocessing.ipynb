{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "#original\n",
    "data = np.array([[3, -1.5, 2, -5.4], [0, 4, -0.3, 2.1], [1, 3.3, -1.9, -4.3]])\n",
    "#parameter axis=0 (columns), axis=1 (rows)\n",
    "print(\"Mean: \",data.mean(axis=0))\n",
    "print(\"Mean: \",data.mean(axis=1))\n",
    "print(\"Standard Deviation: \",data.std(axis=0))\n",
    "\n",
    "#standardized\n",
    "data_standardized = preprocessing.scale(data)\n",
    "print(\"Mean Standardized: \",data_standardized.mean(axis=0))\n",
    "print(\"Standard Deviation Standardized: \",data_standardized.std(axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the data_scaler variable\n",
    "data_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# use fit_trnasform method to fit data and transforms it\n",
    "data_scaled = data_scaler.fit_transform(data)\n",
    "\n",
    "#non-scaled\n",
    "print(\"Min: \",data.min(axis=0))\n",
    "print(\"Max: \",data.max(axis=0))\n",
    "#scaled\n",
    "print(\"Min: \",data_scaled.min(axis=0))\n",
    "print(\"Max: \",data_scaled.max(axis=0))\n",
    "\n",
    "#display scaled array\n",
    "print(data_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The preprocessing.normalize() function can be used as follows \n",
    "data_normalized = preprocessing.normalize(data, norm='l1', axis=0)\n",
    "print(data_normalized) #display the normalized arrary\n",
    "\n",
    "#the normalized array along the columns (features) must return a sum equal to 1.\n",
    "#np.abs() function to evaluate the absolute value of each element in the array.\n",
    "#sum() function to calculate the sum of each column (axis=0)\n",
    "data_norm_abs = np.abs(data_normalized) \n",
    "print(data_norm_abs.sum(axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function binarizes data according to an imposed threshold\n",
    "#The threshold imposed is 1.4, so values greater than 1.4 are mapped to 1, while values less than 1.4 are mapped to 0.\n",
    "\n",
    "data_binarized = preprocessing.Binarizer(threshold=1.4).transform(data)\n",
    "\n",
    "print(data_binarized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#an array with 4 rows (vectors) and 3 columns (features)\n",
    "data = np.array([[1, 1, 2], [0, 2, 3], [1, 0, 1], [0, 1, 0]])\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#an array with 4 rows (vectors) and 3 columns (feature)\n",
    "data = np.array([[1, 1, 2], [0, 2, 3], [1, 0, 1], [0, 1, 0]])\n",
    "print(data)\n",
    "\n",
    "#To encode categorical integer features as a one-hot numeric array\n",
    "#The first row of code sets the encoder, then the fit() function fits the OneHotEncoder object to a data array. \n",
    "encoder = preprocessing.OneHotEncoder()\n",
    "encoder.fit(data)\n",
    "\n",
    "#Transform the data array using one-hot encoding.\n",
    "encoded_vector = encoder.transform([[1, 2, 3]]).toarray()\n",
    "print(encoded_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
