{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "Data = pd.read_csv('../data/source/ratings.csv', sep=';', names=['user', 'item', 'rating', 'timestamp'], header=None)\n",
    "\n",
    "Data = Data.iloc[:,0:3]\n",
    "\n",
    "NumItems = Data.item.nunique() \n",
    "NumUsers = Data.user.nunique()\n",
    "\n",
    "print('Item: ', NumItems)\n",
    "print('Users: ', NumUsers)\n",
    "\n",
    "\n",
    "Data['rating'] = Data['rating'].values.astype(float)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "DataScaled = pd.DataFrame(scaler.fit_transform(Data['rating'].values.reshape(-1,1)))\n",
    "Data['rating'] = DataScaled\n",
    "\n",
    "UserItemMatrix = Data.pivot(index='user', columns='item', values='rating')\n",
    "UserItemMatrix.fillna(0, inplace=True)\n",
    "\n",
    "Users = UserItemMatrix.index.tolist()\n",
    "Items = UserItemMatrix.columns.tolist()\n",
    "\n",
    "#UserItemMatrix = UserItemMatrix.as_matrix()\n",
    "UserItemMatrix = UserItemMatrix.to_numpy()\n",
    "\n",
    "NumInput = NumItems\n",
    "NumHidden1 = 10\n",
    "NumHidden2 = 5\n",
    "\n",
    "tf.disable_v2_behavior() \n",
    "X = tf.placeholder(tf.float64, [None, NumInput])\n",
    "\n",
    "weights = {\n",
    "    'EncoderH1': tf.Variable(tf.random_normal([NumInput, NumHidden1], dtype=tf.float64)),\n",
    "    'EncoderH2': tf.Variable(tf.random_normal([NumHidden1, NumHidden2], dtype=tf.float64)),\n",
    "    'DecoderH1': tf.Variable(tf.random_normal([NumHidden2, NumHidden1], dtype=tf.float64)),\n",
    "    'DecoderH2': tf.Variable(tf.random_normal([NumHidden1, NumInput], dtype=tf.float64)),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'EncoderB1': tf.Variable(tf.random_normal([NumHidden1], dtype=tf.float64)),\n",
    "    'EncoderB2': tf.Variable(tf.random_normal([NumHidden2], dtype=tf.float64)),\n",
    "    'DecoderB1': tf.Variable(tf.random_normal([NumHidden1], dtype=tf.float64)),\n",
    "    'DecoderB2': tf.Variable(tf.random_normal([NumInput], dtype=tf.float64)),\n",
    "}\n",
    "\n",
    "\n",
    "def encoder(x):\n",
    "    Layer1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['EncoderH1']), biases['EncoderB1']))\n",
    "    Layer2 = tf.nn.sigmoid(tf.add(tf.matmul(Layer1, weights['EncoderH2']), biases['EncoderB2']))\n",
    "    return Layer2\n",
    "\n",
    "\n",
    "# Building the decoder\n",
    "\n",
    "def decoder(x):\n",
    "    Layer1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['DecoderH1']), biases['DecoderB1']))\n",
    "    Layer2 = tf.nn.sigmoid(tf.add(tf.matmul(Layer1, weights['DecoderH2']), biases['DecoderB2']))\n",
    "    return Layer2\n",
    "\n",
    "\n",
    "EncoderOp = encoder(X)\n",
    "DecoderOp = decoder(EncoderOp)\n",
    "\n",
    "\n",
    "YPred = DecoderOp\n",
    "\n",
    "YTrue = X\n",
    "\n",
    "loss = tf.losses.mean_squared_error(YTrue, YPred)\n",
    "Optimizer = tf.train.RMSPropOptimizer(0.03).minimize(loss)\n",
    "\n",
    "\n",
    "EvalX = tf.placeholder(tf.int32, )\n",
    "EvalY = tf.placeholder(tf.int32, )\n",
    "Pre, PreOp = tf.metrics.precision(labels=EvalX, predictions=EvalY)\n",
    "\n",
    "Init = tf.global_variables_initializer()\n",
    "LocalInit = tf.local_variables_initializer()\n",
    "\n",
    "PredData = pd.DataFrame()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    Epochs = 120\n",
    "    BatchSize = 200\n",
    "\n",
    "    session.run(Init)\n",
    "    session.run(LocalInit)\n",
    "\n",
    "    NumBatches = int(UserItemMatrix.shape[0] / BatchSize)\n",
    "    UserItemMatrix = np.array_split(UserItemMatrix, NumBatches)\n",
    "    \n",
    "    for i in range(Epochs):\n",
    "\n",
    "        AvgCost = 0\n",
    "\n",
    "        for batch in UserItemMatrix:\n",
    "            _, l = session.run([Optimizer, loss], feed_dict={X: batch})\n",
    "            AvgCost += l\n",
    "\n",
    "        AvgCost /= NumBatches\n",
    "\n",
    "        print(\"Epoch: {} Loss: {}\".format(i + 1, AvgCost))\n",
    "\n",
    "    UserItemMatrix = np.concatenate(UserItemMatrix, axis=0)\n",
    "\n",
    "    Preds = session.run(DecoderOp, feed_dict={X: UserItemMatrix})\n",
    "\n",
    "    PredData = PredData.append(pd.DataFrame(Preds))\n",
    "\n",
    "    PredData = PredData.stack().reset_index(name='rating')\n",
    "    PredData.columns = ['user', 'item', 'rating']\n",
    "    PredData['user'] = PredData['user'].map(lambda value: Users[value])\n",
    "    PredData['item'] = PredData['item'].map(lambda value: Items[value])\n",
    "    \n",
    "    keys = ['user', 'item']\n",
    "    Index1 = PredData.set_index(keys).index\n",
    "    Index2 = Data.set_index(keys).index\n",
    "\n",
    "    TopTenRanked = PredData[~Index1.isin(Index2)]\n",
    "    TopTenRanked = TopTenRanked.sort_values(['user', 'rating'], ascending=[True, False])\n",
    "    TopTenRanked = TopTenRanked.groupby('user').head(10)\n",
    "    \n",
    "    print(TopTenRanked.head(n=10))\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
